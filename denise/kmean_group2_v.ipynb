{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(\"../Resources/telecom_customer_churn.csv\")\n",
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list(orig_df.select_dtypes(exclude=['object']).columns)\n",
    "print(mylist)\n",
    "\n",
    "kmean_df = orig_df[mylist]\n",
    "kmean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_df.drop('Zip Code', axis=1, inplace=True)\n",
    "kmean_df.drop('Latitude', axis=1, inplace=True)\n",
    "kmean_df.drop('Longitude', axis=1, inplace=True)\n",
    "kmean_df.drop('Monthly Charge', axis=1, inplace=True)\n",
    "kmean_df.drop('Total Refunds', axis=1, inplace=True)\n",
    "kmean_df.drop('Total Charges', axis=1, inplace=True)\n",
    "kmean_df.drop('Total Extra Data Charges', axis=1, inplace=True)\n",
    "kmean_df.drop('Total Long Distance Charges', axis=1, inplace=True)\n",
    "kmean_df.drop('Total Revenue', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataframe size: is\",len(kmean_df))\n",
    "kmean_df.dropna( axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "print(\"Dataframe size after drop is\",len(kmean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "data = kmean_df\n",
    "pca = PCA(2)\n",
    " \n",
    "#Transform the data\n",
    "df = pca.fit_transform(data)\n",
    " \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Apply K-Means to the Data\n",
    " \n",
    "#Initialize the class object\n",
    "kmeans = KMeans(n_clusters= 10)\n",
    " \n",
    "#predict the labels of clusters.\n",
    "label = kmeans.fit_predict(df)\n",
    "#kmeans.fit_predict method returns the array of cluster labels each data point belongs to. \n",
    "\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Plotting Label 0 K-Means Clusters\n",
    "#Letâ€™s visualize cluster with label 0 using the matplotlib library.\n",
    "\n",
    " \n",
    "#filter rows of original data\n",
    "filtered_label0 = df[label == 0]\n",
    " \n",
    "#plotting the results\n",
    "plt.scatter(filtered_label0[:,0] , filtered_label0[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Plotting Additional K-Means Clusters\n",
    "\n",
    "#filter rows of original data\n",
    "filtered_label2 = df[label == 2]\n",
    " \n",
    "filtered_label8 = df[label == 8]\n",
    " \n",
    "#Plotting the results\n",
    "plt.scatter(filtered_label2[:,0] , filtered_label2[:,1] , color = 'red')\n",
    "plt.scatter(filtered_label8[:,0] , filtered_label8[:,1] , color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "u_labels = np.unique(label)\n",
    "\n",
    "print(u_labels)\n",
    " \n",
    "#plotting the results:\n",
    " \n",
    "for i in u_labels:\n",
    "    plt.scatter(df[label == i , 0] , df[label == i , 1] , label = i)\n",
    "    \n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    " \n",
    "#Load Data\n",
    "data = kmean_df\n",
    "pca = PCA(2)\n",
    " \n",
    "#Transform the data\n",
    "df = pca.fit_transform(data)\n",
    " \n",
    "#Import KMeans module\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "#Initialize the class object\n",
    "kmeans = KMeans(n_clusters= 10)\n",
    " \n",
    "#predict the labels of clusters.\n",
    "label = kmeans.fit_predict(df)\n",
    " \n",
    "#Getting unique labels\n",
    "u_labels = np.unique(label)\n",
    " \n",
    "#plotting the results:\n",
    "for i in u_labels:\n",
    "    plt.scatter(df[label == i , 0] , df[label == i , 1] , label = i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.askpython.com/python/examples/plot-k-means-clusters-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = kmean_df.columns\n",
    "\n",
    "ms = MinMaxScaler()\n",
    "\n",
    "X = ms.fit_transform(kmean_df)\n",
    "\n",
    "X = pd.DataFrame(X, columns=[cols])\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cs = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10)\n",
    "    kmeans.fit(X)\n",
    "    cs.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), cs)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('CS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    " \n",
    " \n",
    "#Load Data\n",
    "data = kmean_df\n",
    "pca = PCA(2)\n",
    " \n",
    "#Transform the data\n",
    "df = pca.fit_transform(data)\n",
    " \n",
    "#Import KMeans module\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "#Initialize the class object\n",
    "kmeans = KMeans(n_clusters= 2)\n",
    " \n",
    "#predict the labels of clusters.\n",
    "label = kmeans.fit_predict(df)\n",
    " \n",
    "#Getting unique labels\n",
    "u_labels = np.unique(label)\n",
    " \n",
    "#plotting the results:\n",
    "for i in u_labels:\n",
    "    plt.scatter(df[label == i , 0] , df[label == i , 1] , label = i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required modules\n",
    "\n",
    " \n",
    "#Load Data\n",
    "data = kmean_df\n",
    "pca = PCA(2)\n",
    " \n",
    "#Transform the data\n",
    "df = pca.fit_transform(data)\n",
    " \n",
    "#Import KMeans module\n",
    "from sklearn.cluster import KMeans\n",
    " \n",
    "#Initialize the class object\n",
    "kmeans = KMeans(n_clusters= 5)\n",
    " \n",
    "#predict the labels of clusters.\n",
    "label = kmeans.fit_predict(df)\n",
    " \n",
    "#Getting unique labels\n",
    "u_labels = np.unique(label)\n",
    " \n",
    "#plotting the results:\n",
    "for i in u_labels:\n",
    "    plt.scatter(df[label == i , 0] , df[label == i , 1] , label = i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "u_labels = np.unique(label)\n",
    "\n",
    "print(u_labels)\n",
    " \n",
    "#plotting the results:\n",
    " \n",
    "for i in u_labels:\n",
    "    plt.scatter(df[label == i , 0] , df[label == i , 1] , label = i)\n",
    "    \n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.simplilearn.com/tutorials/machine-learning-tutorial/k-means-clustering-algorithm#:~:text=K%2DMeans%20clustering%20is%20an,objects%20belonging%20to%20another%20cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = normalize(kmean_df, norm=\"l1\", axis=0)\n",
    "norm_data = pd.DataFrame(columns=kmean_df.columns, data=norm_data)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "m_norm_data = normalize(kmean_df, norm=\"max\", axis=0)\n",
    "m_norm_data = pd.DataFrame(columns=kmean_df.columns, data=m_norm_data)  # convert back to a dataframe\n",
    "\n",
    "norm_data = pd.DataFrame(columns=kmean_df.columns, data=norm_data)\n",
    "\n",
    "print(norm_data.head(5))\n",
    "print(norm_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = norm_data.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_STATE=50  # for reproducibility and consistency\n",
    "folds=3\n",
    "k_fold = KFold(n_splits=folds, shuffle=True, random_state=RAND_STATE)  # setting generator for k-fold splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of hyperparameters to iterate through\n",
    "# GridSearchCV will try every combination of these hyperparameters and\n",
    "# return the model with the best score via KFold validation\n",
    "hyperparams = {\n",
    "    \"n_clusters\": [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"n_init\": [10, 15, 20],\n",
    "    \"max_iter\": [100, 200, 300, 400, 500],\n",
    "    \"tol\": [.0000001, .000001, .00001, .0001],\n",
    "}\n",
    "\n",
    "k_means = KMeans()  # sets jobs equal to number of cores\n",
    "\n",
    "ensemble = GridSearchCV(\n",
    "    estimator=k_means,\n",
    "    param_grid=hyperparams,\n",
    "    cv=k_fold,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.fit(norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV(cv=KFold(n_splits=3, random_state=50, shuffle=True),\n",
    "       error_score='raise',\n",
    "       estimator=KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
    "       n_clusters=8, n_init=10, \n",
    "       random_state=None, tol=0.0001, verbose=0),\n",
    "       n_jobs=-1,\n",
    "       param_grid={'max_iter': [100, 200, 300, 400, 500], 'n_init': [10, 15, 20], 'tol': [1e-07, 1e-06, 1e-05, 0.0001], 'n_clusters': [2, 3, 4, 5, 6, 7, 8, 9]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
    "       scoring=None, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate labels for data with model with raw data, compute score\n",
    "labels = ensemble.predict(norm_data)\n",
    "score = silhouette_score(norm_data, labels)\n",
    "print(score)\n",
    "print(ensemble.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters to try out for binary classification with KNN\n",
    "bin_params = {\n",
    "    \"n_init\": [10, 15, 20],\n",
    "    \"max_iter\": [100, 200, 300, 400, 500],\n",
    "    \"tol\": [.0000001, .000001, .00001, .0001],\n",
    "}\n",
    "\n",
    "bin_k_means = KMeans(n_clusters=2)  # set 2 clusters\n",
    "\n",
    "binary_ensemble = GridSearchCV(\n",
    "    estimator=bin_k_means,\n",
    "    param_grid=bin_params,\n",
    "    cv=k_fold,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "binary_ensemble.fit(norm_data)  # fit model to data and return best model\n",
    "\n",
    "# Generate labels for data with model with raw data, compute score\n",
    "bin_labels = binary_ensemble.predict(norm_data)\n",
    "bin_score = silhouette_score(norm_data, bin_labels)\n",
    "\n",
    "# Output score to user\n",
    "print(bin_score)\n",
    "print(binary_ensemble.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('PythonAdv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a791cab062a812f57c4cd8ed2766e77836e01fcd09dbc476bdf7c40823bcedc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
